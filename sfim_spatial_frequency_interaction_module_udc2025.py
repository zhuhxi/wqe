import torch
import torch.nn as nn
import torch.nn.functional as F


# ============================================================
# SFIM: Spatialâ€“Frequency Interaction Module (é€šç”¨ç‰ˆæœ¬)
#
# æ€è·¯æ¥æºï¼š
#   - "Integrating Spatial and Frequency Information for
#      Under-Display Camera Image Restoration" (SFIM, UDC, 2025)
#     ä¸­çš„ SDB/FDB/AMIB æ€è·¯ï¼š
#       * ç©ºé—´åˆ†æ”¯: CNN æ•æ‰å±€éƒ¨ç»†èŠ‚ (å™ªå£° & æ¨¡ç³Š)
#       * é¢‘åŸŸåˆ†æ”¯: FFT + é¢‘åŸŸç½‘ç»œæ•æ‰å…¨å±€ç»“æ„ (flare ç­‰)
#       * æ³¨æ„åŠ›å¼èåˆ: è‡ªé€‚åº”èåˆç©ºé—´ & é¢‘åŸŸç‰¹å¾
#
#   - ä»¥åŠ FSI (ICCV'23) çš„ frequencyâ€“spatial åŒåˆ†æ”¯äº¤äº’ã€‚
#
# è¿™é‡Œå®ç°ä¸€ä¸ªç®€åŒ–ä½†å·¥ç¨‹å‹å¥½çš„ç‰ˆæœ¬ï¼š
#   - SFIM_SpatialBranch       : ç©ºé—´å·ç§¯åˆ†æ”¯
#   - SFIM_FrequencyBranch     : é¢‘åŸŸæ»¤æ³¢åˆ†æ”¯ (FFT / iFFT)
#   - SFIM_AttentionFusion     : ç©ºé—´-é¢‘åŸŸæ³¨æ„åŠ›èåˆ
#   - SFIMBlock / SpatialFrequencyInteractionModule :
#        ä¸€ä¸ªå³æ’å³ç”¨çš„ Conv + FFT æ··åˆå—
#
# è¾“å…¥ / è¾“å‡º: (B, C, H, W) -> (B, C, H, W)
# ============================================================


# ------------------------------------------------------------
# 1. ç©ºé—´åˆ†æ”¯: SDB é£æ ¼ (ç®€å•æ®‹å·®å·ç§¯å—)
# ------------------------------------------------------------

class SFIM_SpatialBranch(nn.Module):
    """
    Spatial Branch (SDB-like).

    éå¸¸æ ‡å‡†çš„æ®‹å·®å·ç§¯å—ï¼š
        R_s(x) = Conv3x3(BN + ReLU(Conv3x3(x)))

    Args:
        channels: è¾“å…¥/è¾“å‡ºé€šé“æ•° C
    """

    def __init__(self, channels: int):
        super().__init__()
        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(channels)
        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(channels)
        self.act = nn.ReLU(inplace=True)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        y = self.act(self.bn1(self.conv1(x)))
        y = self.bn2(self.conv2(y))
        # æ®‹å·®å›åŠ 
        out = self.act(x + y)
        return out


# ------------------------------------------------------------
# 2. é¢‘åŸŸåˆ†æ”¯: FDB é£æ ¼ (FFT + 1x1 conv æ»¤æ³¢ + iFFT)
# ------------------------------------------------------------

class SFIM_FrequencyBranch(nn.Module):
    """
    Frequency Branch (FDB-like).

    ç®€åŒ–å®ç°ï¼š
      - å¯¹è¾“å…¥åš 2D FFT
      - æŠŠå®éƒ¨ / è™šéƒ¨åœ¨é€šé“ç»´æ‹¼æ¥
      - é¢‘åŸŸä¸Šç”¨ 1x1 Conv + ReLU + 1x1 Conv åšçº¿æ€§å˜æ¢
      - å† iFFT å›åˆ°ç©ºé—´åŸŸ

    è¾“å…¥ / è¾“å‡º: (B, C, H, W) -> (B, C, H, W)
    """

    def __init__(self, channels: int):
        super().__init__()
        self.channels = channels
        self.conv1 = nn.Conv2d(2 * channels, 2 * channels, kernel_size=1, bias=True)
        self.conv2 = nn.Conv2d(2 * channels, 2 * channels, kernel_size=1, bias=True)
        self.act = nn.ReLU(inplace=True)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        B, C, H, W = x.shape
        assert C == self.channels

        # 2D FFT: å¾—åˆ° complex ç‰¹å¾
        spec = torch.fft.fft2(x, norm="ortho")  # (B, C, H, W), complex
        real = spec.real
        imag = spec.imag

        # åœ¨é€šé“ç»´æ‹¼æ¥å®éƒ¨å’Œè™šéƒ¨
        feat = torch.cat([real, imag], dim=1)  # (B, 2C, H, W)
        feat = self.act(self.conv1(feat))
        feat = self.conv2(feat)

        # å†æ‹†å›å®éƒ¨ / è™šéƒ¨
        real2, imag2 = torch.chunk(feat, 2, dim=1)
        spec_new = torch.complex(real2, imag2)

        # iFFT å›åˆ°ç©ºé—´åŸŸï¼Œå–å®éƒ¨
        x_rec = torch.fft.ifft2(spec_new, norm="ortho").real  # (B, C, H, W)
        return x_rec


# ------------------------------------------------------------
# 3. ç©ºé—´-é¢‘åŸŸæ³¨æ„åŠ›èåˆå•å…ƒ
#    ç±»ä¼¼ AMIB çš„å±€éƒ¨ç‰ˆæœ¬ï¼š
#      - concat(Fs, Ff) -> Conv1x1 -> 2C é€šé“çš„ gate
#      - æ‹†æˆ g_s, g_f âˆˆ (0,1)ï¼Œåˆ†åˆ«è°ƒåˆ¶ Fs, Ff
#      - fused = g_s * Fs + g_f * Ff
# ------------------------------------------------------------

class SFIM_AttentionFusion(nn.Module):
    """
    Attention-based Spatialâ€“Frequency Fusion.

    Inputs:
        Fs: ç©ºé—´åˆ†æ”¯è¾“å‡º (B, C, H, W)
        Ff: é¢‘åŸŸåˆ†æ”¯è¾“å‡º (B, C, H, W)

    Output:
        fused: (B, C, H, W)
    """

    def __init__(self, channels: int):
        super().__init__()
        self.channels = channels
        self.fuse_conv = nn.Conv2d(
            in_channels=2 * channels,
            out_channels=2 * channels,
            kernel_size=1,
            bias=True,
        )
        self.bn = nn.BatchNorm2d(2 * channels)
        self.act = nn.ReLU(inplace=True)
        self.sigmoid = nn.Sigmoid()

    def forward(self, Fs: torch.Tensor, Ff: torch.Tensor) -> torch.Tensor:
        B, C, H, W = Fs.shape
        assert Ff.shape == Fs.shape

        joint = torch.cat([Fs, Ff], dim=1)  # (B, 2C, H, W)
        gate = self.sigmoid(self.bn(self.fuse_conv(joint)))  # (B, 2C, H, W)

        g_s, g_f = torch.chunk(gate, 2, dim=1)  # (B, C, H, W) each

        Fs_mod = Fs * g_s
        Ff_mod = Ff * g_f

        fused = Fs_mod + Ff_mod  # (B, C, H, W)
        return fused


# ------------------------------------------------------------
# 4. æ•´ä½“ SFIM Blockï¼šConv + FFT + äº¤äº’
# ------------------------------------------------------------

class SFIMBlock(nn.Module):
    """
    Spatialâ€“Frequency Interaction Module (SFIM Block).

    Pipeline:
      1) Fs = SpatialBranch(x)
      2) Ff = FrequencyBranch(x)
      3) F_fused = AttentionFusion(Fs, Ff)
      4) out = x + Conv1x1(BN + ReLU(F_fused))

    è¾“å…¥ / è¾“å‡º: (B, C, H, W) -> (B, C, H, W)

    ç”¨æ³•ç¤ºä¾‹:
      - ç›´æ¥æ›¿æ¢ UNet / EcNet encoder çš„æŸä¸ªæ®‹å·®å—:
            self.block3 = SFIMBlock(channels=64)
      - æˆ–ä½œä¸º bottleneck å‰åçš„â€œå»æ¨¡ç³Š + å»å™ªå£°â€ä¸“ç”¨æ¨¡å—ã€‚
    """

    def __init__(self, channels: int):
        super().__init__()
        self.spatial = SFIM_SpatialBranch(channels)
        self.freq = SFIM_FrequencyBranch(channels)
        self.fusion = SFIM_AttentionFusion(channels)

        # è¾“å‡ºæŠ•å½± + æ®‹å·®
        self.out_conv = nn.Conv2d(channels, channels, kernel_size=1, bias=False)
        self.out_bn = nn.BatchNorm2d(channels)
        self.out_act = nn.ReLU(inplace=True)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        Fs = self.spatial(x)
        Ff = self.freq(x)
        fused = self.fusion(Fs, Ff)       # (B, C, H, W)

        y = self.out_bn(self.out_conv(fused))
        y = self.out_act(y)

        out = x + y
        return out


# ç»™ä¸€ä¸ªåˆ«åï¼Œæ–¹ä¾¿ä½ åœ¨åˆ«çš„æ–‡ä»¶é‡Œç”¨å…¨åè°ƒç”¨
class SpatialFrequencyInteractionModule(SFIMBlock):
    """
    åˆ«åï¼šSpatialFrequencyInteractionModule
    å®é™…ä¸Šå°±æ˜¯ SFIMBlockã€‚
    """
    pass


# ============================================================
# 5. æµ‹è¯•è„šæœ¬
#    - Forward shape æ£€æŸ¥
#    - NNI ç»Ÿè®¡ FLOPs / Params
# ============================================================

def build_test_module(name: str):
    """
    æ”¯æŒæµ‹è¯•:
      - "spatial" : SFIM_SpatialBranch
      - "freq"    : SFIM_FrequencyBranch
      - "fuse"    : SFIM_AttentionFusion
      - "sfim"    : SFIMBlock / SpatialFrequencyInteractionModule
    """
    name = name.lower()
    C = 32
    H = W = 32

    x = torch.rand(1, C, H, W)
    if name == "spatial":
        module = SFIM_SpatialBranch(channels=C)
        inputs = (x,)
    elif name == "freq":
        module = SFIM_FrequencyBranch(channels=C)
        inputs = (x,)
    elif name == "fuse":
        module = SFIM_AttentionFusion(channels=C)
        Fs = torch.rand(1, C, H, W)
        Ff = torch.rand(1, C, H, W)
        inputs = (Fs, Ff)
    elif name == "sfim":
        module = SFIMBlock(channels=C)
        inputs = (x,)
    else:
        raise ValueError(f"Unknown module name: {name}")

    return module, inputs


if __name__ == "__main__":
    # è¿™é‡Œæ”¹åå­—å°±èƒ½æµ‹ä¸åŒæ¨¡å—:
    # "spatial", "freq", "fuse", "sfim"
    module_name = "sfim"

    model, inputs = build_test_module(module_name)
    in_shapes = ", ".join(str(t.shape) for t in inputs)

    print(f"ğŸ”§ Testing SFIM module: {module_name}")
    print(f"   Input shape(s): {in_shapes}")

    # --- Forward æµ‹è¯• ---
    try:
        with torch.no_grad():
            out = model(*inputs)

        if isinstance(out, tuple):
            out_shapes = ", ".join(str(t.shape) for t in out)
        else:
            out_shapes = str(out.shape)

        print(f"âœ… Forward Pass Success: {in_shapes} â†’ {out_shapes}")
    except Exception as e:
        print(f"âŒ Forward Failed: {e}")

    # --- FLOPs / Params ---
    try:
        from nni.compression.utils.counter import count_flops_params

        flops, params, _ = count_flops_params(model, x=inputs)
        print(f"ğŸ“Š FLOPs:  {flops / 1e6:.2f} MFLOPs | Params: {params / 1e6:.4f} M")
    except ImportError:
        print("âš ï¸ NNI not installed. Run: pip install nni")
    except Exception as e:
        print(f"âš ï¸ FLOPs/Params counting failed: {e}")
